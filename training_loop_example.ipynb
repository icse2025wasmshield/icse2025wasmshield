{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/datascience/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import wasmshield\n",
    "import wasmshield.training.trainer\n",
    "import wasmshield.utils\n",
    "import wasmshield.preprocessing\n",
    "import joblib\n",
    "import os\n",
    "import tqdm\n",
    "import pytorch_lamb\n",
    "import lightly\n",
    "import timm\n",
    "\n",
    "size = 64\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "semantic_X=joblib.load('evaluation_logs/semantic_X')\n",
    "semantic_train_idx =joblib.load('evaluation_logs/semantic_train_idx')\n",
    "semantic_test_idx=joblib.load('evaluation_logs/semantic_test_idx')\n",
    "semantic_y=joblib.load('evaluation_logs/semantic_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14860/14860 [00:03<00:00, 3921.61it/s] \n",
      "100%|██████████| 3715/3715 [00:01<00:00, 3284.44it/s]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_set, \n",
    "    test_set, \n",
    "    wasm_bench_train_set, \n",
    "    wasm_bench_test_set, \n",
    "    obfuscated_train_set, \n",
    "    obfuscated_test_set, \n",
    "    msr_train_set, \n",
    "    msr_test_set,\n",
    ") = wasmshield.utils.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from fastai.layers import ConvLayer, NormType\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"Self attention layer for `n_channels`.\"\n",
    "    def __init__(self, n_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query,self.key,self.value = [self._conv(n_channels, c) for c in (n_channels//8,n_channels//8,n_channels)]\n",
    "        self.gamma = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def _conv(self,n_in,n_out):\n",
    "        return ConvLayer(n_in, n_out, ks=1, ndim=1, norm_type=NormType.Spectral, act_cls=None, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Notation from the paper.\n",
    "        size = x.size()\n",
    "        x = x.view(*size[:2],-1)\n",
    "        f,g,h = self.query(x),self.key(x),self.value(x)\n",
    "        beta = F.softmax(torch.bmm(f.transpose(1,2), g), dim=1)\n",
    "        o = self.gamma * torch.bmm(h, beta) + x\n",
    "        return o.view(*size).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128]                 --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 64, 64]          128\n",
      "|    └─ReLU: 2-2                         [-1, 32, 64, 64]          --\n",
      "|    └─BatchNorm2d: 2-3                  [-1, 32, 64, 64]          64\n",
      "|    └─ResBlock: 2-4                     [-1, 32, 64, 64]          --\n",
      "|    |    └─Sequential: 3-1              [-1, 32, 64, 64]          9,312\n",
      "|    └─ResBlock: 2-5                     [-1, 32, 64, 64]          --\n",
      "|    |    └─Sequential: 3-2              [-1, 32, 64, 64]          9,312\n",
      "|    └─ResBlock: 2-6                     [-1, 32, 64, 64]          --\n",
      "|    |    └─Sequential: 3-3              [-1, 32, 64, 64]          9,312\n",
      "|    └─BatchNorm2d: 2-7                  [-1, 32, 64, 64]          64\n",
      "|    └─MaxPool2d: 2-8                    [-1, 32, 32, 32]          --\n",
      "|    └─SelfAttention: 2-9                [-1, 32, 32, 32]          --\n",
      "|    |    └─ConvLayer: 3-4               [-1, 4, 1024]             128\n",
      "|    |    └─ConvLayer: 3-5               [-1, 4, 1024]             128\n",
      "|    |    └─ConvLayer: 3-6               [-1, 32, 1024]            1,024\n",
      "|    └─Conv2d: 2-10                      [-1, 64, 32, 32]          2,112\n",
      "|    └─ReLU: 2-11                        [-1, 64, 32, 32]          --\n",
      "|    └─BatchNorm2d: 2-12                 [-1, 64, 32, 32]          128\n",
      "|    └─ResBlock: 2-13                    [-1, 64, 32, 32]          --\n",
      "|    |    └─Sequential: 3-7              [-1, 64, 32, 32]          37,056\n",
      "|    └─ResBlock: 2-14                    [-1, 64, 32, 32]          --\n",
      "|    |    └─Sequential: 3-8              [-1, 64, 32, 32]          37,056\n",
      "|    └─ResBlock: 2-15                    [-1, 64, 32, 32]          --\n",
      "|    |    └─Sequential: 3-9              [-1, 64, 32, 32]          37,056\n",
      "|    └─BatchNorm2d: 2-16                 [-1, 64, 32, 32]          128\n",
      "|    └─MaxPool2d: 2-17                   [-1, 64, 16, 16]          --\n",
      "|    └─SelfAttention: 2-18               [-1, 64, 16, 16]          --\n",
      "|    |    └─ConvLayer: 3-10              [-1, 8, 256]              512\n",
      "|    |    └─ConvLayer: 3-11              [-1, 8, 256]              512\n",
      "|    |    └─ConvLayer: 3-12              [-1, 64, 256]             4,096\n",
      "|    └─ResBlock: 2-19                    [-1, 64, 16, 16]          --\n",
      "|    |    └─Sequential: 3-13             [-1, 64, 16, 16]          37,056\n",
      "|    └─ResBlock: 2-20                    [-1, 64, 16, 16]          --\n",
      "|    |    └─Sequential: 3-14             [-1, 64, 16, 16]          37,056\n",
      "|    └─ResBlock: 2-21                    [-1, 64, 16, 16]          --\n",
      "|    |    └─Sequential: 3-15             [-1, 64, 16, 16]          37,056\n",
      "|    └─BatchNorm2d: 2-22                 [-1, 64, 16, 16]          128\n",
      "|    └─MaxPool2d: 2-23                   [-1, 64, 8, 8]            --\n",
      "|    └─SelfAttention: 2-24               [-1, 64, 8, 8]            --\n",
      "|    |    └─ConvLayer: 3-16              [-1, 8, 64]               512\n",
      "|    |    └─ConvLayer: 3-17              [-1, 8, 64]               512\n",
      "|    |    └─ConvLayer: 3-18              [-1, 64, 64]              4,096\n",
      "|    └─Conv2d: 2-25                      [-1, 128, 8, 8]           8,320\n",
      "|    └─ReLU: 2-26                        [-1, 128, 8, 8]           --\n",
      "|    └─BatchNorm2d: 2-27                 [-1, 128, 8, 8]           256\n",
      "|    └─ResBlock: 2-28                    [-1, 128, 8, 8]           --\n",
      "|    |    └─Sequential: 3-19             [-1, 128, 8, 8]           147,840\n",
      "|    └─ResBlock: 2-29                    [-1, 128, 8, 8]           --\n",
      "|    |    └─Sequential: 3-20             [-1, 128, 8, 8]           147,840\n",
      "|    └─ResBlock: 2-30                    [-1, 128, 8, 8]           --\n",
      "|    |    └─Sequential: 3-21             [-1, 128, 8, 8]           147,840\n",
      "|    └─BatchNorm2d: 2-31                 [-1, 128, 8, 8]           256\n",
      "|    └─MaxPool2d: 2-32                   [-1, 128, 4, 4]           --\n",
      "|    └─SelfAttention: 2-33               [-1, 128, 4, 4]           --\n",
      "|    |    └─ConvLayer: 3-22              [-1, 16, 16]              2,048\n",
      "|    |    └─ConvLayer: 3-23              [-1, 16, 16]              2,048\n",
      "|    |    └─ConvLayer: 3-24              [-1, 128, 16]             16,384\n",
      "|    └─ResBlock: 2-34                    [-1, 128, 4, 4]           --\n",
      "|    |    └─Sequential: 3-25             [-1, 128, 4, 4]           147,840\n",
      "|    └─ResBlock: 2-35                    [-1, 128, 4, 4]           --\n",
      "|    |    └─Sequential: 3-26             [-1, 128, 4, 4]           147,840\n",
      "|    └─ResBlock: 2-36                    [-1, 128, 4, 4]           --\n",
      "|    |    └─Sequential: 3-27             [-1, 128, 4, 4]           147,840\n",
      "|    └─BatchNorm2d: 2-37                 [-1, 128, 4, 4]           256\n",
      "|    └─MaxPool2d: 2-38                   [-1, 128, 2, 2]           --\n",
      "|    └─SelfAttention: 2-39               [-1, 128, 2, 2]           --\n",
      "|    |    └─ConvLayer: 3-28              [-1, 16, 4]               2,048\n",
      "|    |    └─ConvLayer: 3-29              [-1, 16, 4]               2,048\n",
      "|    |    └─ConvLayer: 3-30              [-1, 128, 4]              16,384\n",
      "├─AdaptiveMaxPool2d: 1-2                 [-1, 128, 1, 1]           --\n",
      "├─Sequential: 1                          []                        --\n",
      "|    └─AdaptiveMaxPool2d: 2-40           [-1, 128, 1, 1]           --\n",
      "|    └─Flatten: 2-41                     [-1, 128]                 --\n",
      "==========================================================================================\n",
      "Total params: 1,201,632\n",
      "Trainable params: 1,201,632\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 296.84\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 15.58\n",
      "Params size (MB): 4.58\n",
      "Estimated Total Size (MB): 20.21\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torchsummary, torch.nn as nn\n",
    "\n",
    "\n",
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, n, att=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(n, n, kernel_size = 3, stride = 1, padding = 1,),\n",
    "            torch.nn.BatchNorm2d(n),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.conv(x)+x)\n",
    "    \n",
    "class ConvRes(torch.nn.Module):\n",
    "    def __init__(self, att=False, reduction=None, ll=3):\n",
    "        super().__init__()\n",
    "\n",
    "        n = 32\n",
    "        m = 64\n",
    "        o = 64\n",
    "        p = 128\n",
    "        q = 128\n",
    "\n",
    "        self.num = 0\n",
    "\n",
    "        layers_channels = [\n",
    "\n",
    "            (ll,n),\n",
    "\n",
    "            (ll,m),\n",
    "            (ll,o),\n",
    "\n",
    "            (ll,p),\n",
    "            (ll,q),\n",
    "\n",
    "\n",
    "        ]\n",
    "        \n",
    "        blocks = []\n",
    "\n",
    "        last_chan = 3+self.num\n",
    "\n",
    "        for nb_blocks_per_layer, new_chan in layers_channels:\n",
    "\n",
    "            if last_chan != new_chan:\n",
    "\n",
    "                blocks.extend(\n",
    "                    [\n",
    "                        nn.Conv2d(last_chan, new_chan, kernel_size = 1, stride = 1,),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        torch.nn.BatchNorm2d(new_chan),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            blocks.extend([ResBlock(new_chan, att=att) for _ in range(nb_blocks_per_layer)])\n",
    "            blocks.append(torch.nn.BatchNorm2d(new_chan))\n",
    "            blocks.append(nn.MaxPool2d(2,2))\n",
    "            if att==True:\n",
    "                blocks.append(SelfAttention(new_chan))\n",
    "\n",
    "            last_chan = new_chan\n",
    "\n",
    "        self.reduction = (\n",
    "            torch.nn.AdaptiveAvgPool2d(1) if reduction == 'avg'\n",
    "            else (\n",
    "                torch.nn.AdaptiveMaxPool2d(1) if reduction == 'max'\n",
    "                else torch.nn.Identity()\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "\n",
    "            *blocks,\n",
    "            self.reduction,\n",
    "            torch.nn.Flatten(),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x \n",
    "\n",
    "torchsummary.summary(ConvRes(att=True, reduction='max'), (3,64,64))\n",
    "\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training \n",
      "Training trainable_model.name='Emprique60_2_ResBin18_woSA_b64_i64_pil_v128_rmax_t015'\n",
      "\n",
      "==========\n",
      "[<BatchType.obfuscated_formai: 0>, <BatchType.mutated_formai: 3>, <BatchType.mutated_optim_levels_formai: 2>, <BatchType.optim_level_formai: 1>, <BatchType.mutated_wasm_bench: 4>, <BatchType.mutated_msr: 5>, <BatchType.semantic_classification: 6>]\n",
      "==========\n",
      "Stepping backward.\n",
      "| epoch = 1 | batch = 1 | loss = 4.29028 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 1 | batch = 2 | loss = 3.27331 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 1 | batch = 3 | loss = 3.03764 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 1 | batch = 4 | loss = 2.84464 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 1 | batch = 5 | loss = 2.78920 |\n",
      "\n",
      "\n",
      " Test_loss= 3.98969140506926 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 3.1925763130187987 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 3.3112929264704385 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 2.854667584101359 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 2.5980478127797446 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.6041210492451987 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 2 | batch = 1 | loss = 2.57753 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 2 | batch = 2 | loss = 2.59458 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 2 | batch = 3 | loss = 2.53479 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 2 | batch = 4 | loss = 2.37292 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 2 | batch = 5 | loss = 2.45073 |\n",
      "\n",
      "\n",
      " Test_loss= 3.861763420559111 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 2.7901219209035237 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 2.8425333897272744 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 2.319168965021769 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 2.18221116065979 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.4260735511779785 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 3 | batch = 1 | loss = 2.29205 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 3 | batch = 2 | loss = 2.26745 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 3 | batch = 3 | loss = 2.11557 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 3 | batch = 4 | loss = 2.26218 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 3 | batch = 5 | loss = 2.12186 |\n",
      "\n",
      "\n",
      " Test_loss= 3.7376290275937034 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 2.233372195561727 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 2.2188372015953064 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.569643219312032 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.5388308763504028 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0574707984924316 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 4 | batch = 1 | loss = 2.10192 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 4 | batch = 2 | loss = 2.19879 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 4 | batch = 3 | loss = 2.05882 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 4 | batch = 4 | loss = 1.99964 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 4 | batch = 5 | loss = 2.00594 |\n",
      "\n",
      "\n",
      " Test_loss= 3.705120495387486 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 2.0800667444864906 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 2.0924120446046195 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.4803313414255779 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4939149618148804 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.2021685043970742 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 5 | batch = 1 | loss = 1.97895 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 5 | batch = 2 | loss = 2.10940 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 5 | batch = 3 | loss = 2.00076 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 5 | batch = 4 | loss = 1.80831 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 5 | batch = 5 | loss = 1.91070 |\n",
      "\n",
      "\n",
      " Test_loss= 3.50258503641401 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 2.0264715909957887 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 2.079772710800171 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.4462911287943523 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.5654623905817668 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.2317700386047363 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 6 | batch = 1 | loss = 1.85329 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 6 | batch = 2 | loss = 1.87635 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 6 | batch = 3 | loss = 1.79456 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 6 | batch = 4 | loss = 1.78906 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 6 | batch = 5 | loss = 1.81425 |\n",
      "\n",
      "\n",
      " Test_loss= 3.405648640223912 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.900737420717875 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.92353821794192 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.3314661979675293 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4972315629323323 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.1198389530181885 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 7 | batch = 1 | loss = 1.94245 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 7 | batch = 2 | loss = 1.78264 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 7 | batch = 3 | loss = 1.78568 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 7 | batch = 4 | loss = 1.72540 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 7 | batch = 5 | loss = 1.69288 |\n",
      "\n",
      "\n",
      " Test_loss= 3.163920924777076 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.7430042505264283 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.7593640983104706 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.2541968027750652 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.6310441891352336 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.02716326713562 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 8 | batch = 1 | loss = 1.77156 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 8 | batch = 2 | loss = 1.82977 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 8 | batch = 3 | loss = 1.76523 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 8 | batch = 4 | loss = 1.72242 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 8 | batch = 5 | loss = 1.64677 |\n",
      "\n",
      "\n",
      " Test_loss= 3.0348910888036094 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.5863780498504638 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.672430505355199 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.1015756924947102 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.5476524035135906 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9829755226771038 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 9 | batch = 1 | loss = 1.62221 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 9 | batch = 2 | loss = 1.73854 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 9 | batch = 3 | loss = 1.68079 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 9 | batch = 4 | loss = 1.70344 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 9 | batch = 5 | loss = 1.73869 |\n",
      "\n",
      "\n",
      " Test_loss= 2.987464036260332 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.4999433914820353 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.6035381356875102 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9954159657160441 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2646936178207397 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.003730535507202 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 10 | batch = 1 | loss = 1.67098 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 10 | batch = 2 | loss = 1.53568 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 10 | batch = 3 | loss = 1.63757 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 10 | batch = 4 | loss = 1.57478 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 10 | batch = 5 | loss = 1.61562 |\n",
      "\n",
      "\n",
      " Test_loss= 3.3687395141238254 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.5971837123235069 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.6840061942736309 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.205933928489685 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4139713446299236 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0021584828694663 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 11 | batch = 1 | loss = 1.59877 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 11 | batch = 2 | loss = 1.50915 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 11 | batch = 3 | loss = 1.60916 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 11 | batch = 4 | loss = 1.49733 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 11 | batch = 5 | loss = 1.58078 |\n",
      "\n",
      "\n",
      " Test_loss= 3.1604753902980263 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.6543536265691123 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.7067776322364807 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.2079215844472249 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3668935696283977 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9317810535430908 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 12 | batch = 1 | loss = 1.50834 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 12 | batch = 2 | loss = 1.54253 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 12 | batch = 3 | loss = 1.48935 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 12 | batch = 4 | loss = 1.50993 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 12 | batch = 5 | loss = 1.52743 |\n",
      "\n",
      "\n",
      " Test_loss= 3.0620408966427757 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.437220009167989 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.411060482263565 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9161074757575989 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3892212708791096 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.084266106287638 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 13 | batch = 1 | loss = 1.51315 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 13 | batch = 2 | loss = 1.53175 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 13 | batch = 3 | loss = 1.54487 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 13 | batch = 4 | loss = 1.54293 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 13 | batch = 5 | loss = 1.48121 |\n",
      "\n",
      "\n",
      " Test_loss= 3.079226726577396 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.5673280159632366 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.5930105149745941 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.1690820455551147 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.322872241338094 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.2113200028737388 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 14 | batch = 1 | loss = 1.54242 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 14 | batch = 2 | loss = 1.50993 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 14 | batch = 3 | loss = 1.52809 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 14 | batch = 4 | loss = 1.55587 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 14 | batch = 5 | loss = 1.48204 |\n",
      "\n",
      "\n",
      " Test_loss= 2.975838734990075 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.3989946683247885 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.4582960903644562 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9954847097396851 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2339469194412231 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0029869874318442 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 15 | batch = 1 | loss = 1.36594 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 15 | batch = 2 | loss = 1.48525 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 15 | batch = 3 | loss = 1.46870 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 15 | batch = 4 | loss = 1.41268 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 15 | batch = 5 | loss = 1.42284 |\n",
      "\n",
      "\n",
      " Test_loss= 3.1507439272744318 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.591534392038981 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.6751133700211842 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.2225420077641804 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.547456940015157 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.8412845532099407 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 16 | batch = 1 | loss = 1.54794 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 16 | batch = 2 | loss = 1.44866 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 16 | batch = 3 | loss = 1.49731 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 16 | batch = 4 | loss = 1.40240 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 16 | batch = 5 | loss = 1.41520 |\n",
      "\n",
      "\n",
      " Test_loss= 2.951959394273304 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.3085588375727335 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.3536986509958904 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9158689379692078 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.25920303662618 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9249626000722249 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 17 | batch = 1 | loss = 1.52848 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 17 | batch = 2 | loss = 1.48538 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 17 | batch = 3 | loss = 1.46246 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 17 | batch = 4 | loss = 1.50505 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 17 | batch = 5 | loss = 1.39604 |\n",
      "\n",
      "\n",
      " Test_loss= 2.8796513023830594 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.3965748469034829 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.388973891735077 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9167581995328268 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1905503273010254 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.1137577295303345 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 18 | batch = 1 | loss = 1.46346 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 18 | batch = 2 | loss = 1.44168 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 18 | batch = 3 | loss = 1.46675 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 18 | batch = 4 | loss = 1.29494 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 18 | batch = 5 | loss = 1.42256 |\n",
      "\n",
      "\n",
      " Test_loss= 3.0474610271907987 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.3375148932139078 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.336360365152359 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8986884554227194 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4886974493662517 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.8271006345748901 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 19 | batch = 1 | loss = 1.44509 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 19 | batch = 2 | loss = 1.42864 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 19 | batch = 3 | loss = 1.33156 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 19 | batch = 4 | loss = 1.39209 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 19 | batch = 5 | loss = 1.35090 |\n",
      "\n",
      "\n",
      " Test_loss= 2.9636600414911904 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.4388081550598146 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.447878897190094 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.0346990823745728 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3301738500595093 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.122441609700521 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 20 | batch = 1 | loss = 1.40130 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 20 | batch = 2 | loss = 1.42971 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 20 | batch = 3 | loss = 1.32262 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 20 | batch = 4 | loss = 1.37332 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 20 | batch = 5 | loss = 1.42226 |\n",
      "\n",
      "\n",
      " Test_loss= 3.023383378982544 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.261955761909485 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2755495806535084 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8547377586364746 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2424193223317463 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0127563079198203 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 21 | batch = 1 | loss = 1.37578 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 21 | batch = 2 | loss = 1.38167 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 21 | batch = 3 | loss = 1.37632 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 21 | batch = 4 | loss = 1.35595 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 21 | batch = 5 | loss = 1.43839 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6910385290781655 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.4476011117299397 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.4953519900639851 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.0919565359751384 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4304333527882893 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9635728200276692 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 22 | batch = 1 | loss = 1.26918 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 22 | batch = 2 | loss = 1.22659 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 22 | batch = 3 | loss = 1.35210 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 22 | batch = 4 | loss = 1.27863 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 22 | batch = 5 | loss = 1.39270 |\n",
      "\n",
      "\n",
      " Test_loss= 2.8037748620623635 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2602934439977012 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.24688321352005 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9216086268424988 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3510705629984539 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.2014667987823486 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 23 | batch = 1 | loss = 1.31881 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 23 | batch = 2 | loss = 1.30034 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 23 | batch = 3 | loss = 1.27023 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 23 | batch = 4 | loss = 1.31340 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 23 | batch = 5 | loss = 1.27357 |\n",
      "\n",
      "\n",
      " Test_loss= 2.8453393720445184 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1788111925125122 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.208786855141322 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.755047599474589 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3006199995676677 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9907398621241252 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 24 | batch = 1 | loss = 1.32883 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 24 | batch = 2 | loss = 1.36331 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 24 | batch = 3 | loss = 1.27303 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 24 | batch = 4 | loss = 1.25472 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 24 | batch = 5 | loss = 1.22585 |\n",
      "\n",
      "\n",
      " Test_loss= 2.9694623720078237 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.400959316889445 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.4131494164466858 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.0216018160184224 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3431282043457031 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.017587979634603 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 25 | batch = 1 | loss = 1.32622 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 25 | batch = 2 | loss = 1.28561 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 25 | batch = 3 | loss = 1.21230 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 25 | batch = 4 | loss = 1.33355 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 25 | batch = 5 | loss = 1.32167 |\n",
      "\n",
      "\n",
      " Test_loss= 2.8674267587207614 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2820314248402915 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2794944147268932 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8587849338849386 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3315986792246501 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9237162669499714 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 26 | batch = 1 | loss = 1.23989 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 26 | batch = 2 | loss = 1.29740 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 26 | batch = 3 | loss = 1.24284 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 26 | batch = 4 | loss = 1.26353 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 26 | batch = 5 | loss = 1.30845 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7385926246643066 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.291469923655192 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.293157418568929 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8599757353464762 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.299013574918111 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.017126679420471 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 27 | batch = 1 | loss = 1.28400 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 27 | batch = 2 | loss = 1.17619 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 27 | batch = 3 | loss = 1.20708 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 27 | batch = 4 | loss = 1.20697 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 27 | batch = 5 | loss = 1.19975 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7579158941904702 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1763405561447144 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1756454308827717 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8126029968261719 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2997101545333862 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.2793660163879395 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 28 | batch = 1 | loss = 1.18373 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 28 | batch = 2 | loss = 1.25859 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 28 | batch = 3 | loss = 1.14217 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 28 | batch = 4 | loss = 1.23660 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 28 | batch = 5 | loss = 1.21469 |\n",
      "\n",
      "\n",
      " Test_loss= 2.683272361755371 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2174593846003214 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2201236486434937 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8672317465146383 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1672444740931194 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0480897029240928 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 29 | batch = 1 | loss = 1.22787 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 29 | batch = 2 | loss = 1.23013 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 29 | batch = 3 | loss = 1.19968 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 29 | batch = 4 | loss = 1.14323 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 29 | batch = 5 | loss = 1.22847 |\n",
      "\n",
      "\n",
      " Test_loss= 2.8516948393413 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1463482220967611 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.199654797712962 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7931553721427917 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 0.9974383513132731 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.119773745536804 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 30 | batch = 1 | loss = 1.18722 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 30 | batch = 2 | loss = 1.19488 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 30 | batch = 3 | loss = 1.16984 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 30 | batch = 4 | loss = 1.20060 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 30 | batch = 5 | loss = 1.16929 |\n",
      "\n",
      "\n",
      " Test_loss= 2.823695165770394 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1847030798594156 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.219528357187907 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8669639229774475 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2855151494344075 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.202112913131714 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 31 | batch = 1 | loss = 1.22262 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 31 | batch = 2 | loss = 1.26404 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 31 | batch = 3 | loss = 1.31908 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 31 | batch = 4 | loss = 1.24375 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 31 | batch = 5 | loss = 1.19037 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7436930281775336 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.174232264359792 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2109185059865315 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7688709100087484 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 0.9532479842503866 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.100781043370565 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 32 | batch = 1 | loss = 1.13356 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 32 | batch = 2 | loss = 1.10440 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 32 | batch = 3 | loss = 1.26897 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 32 | batch = 4 | loss = 1.14783 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 32 | batch = 5 | loss = 1.13540 |\n",
      "\n",
      "\n",
      " Test_loss= 2.717924055599031 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.3248385508855185 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2979931433995564 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.931958814462026 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2030371030171711 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9776838620503743 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 33 | batch = 1 | loss = 1.12781 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 33 | batch = 2 | loss = 1.22833 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 33 | batch = 3 | loss = 1.14920 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 33 | batch = 4 | loss = 1.08824 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 33 | batch = 5 | loss = 1.21818 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6892059700829645 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.3246788501739504 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.3325945734977722 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9729898373285929 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1823876698811848 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.984576900800069 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 34 | batch = 1 | loss = 1.18951 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 34 | batch = 2 | loss = 1.18200 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 34 | batch = 3 | loss = 1.17934 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 34 | batch = 4 | loss = 1.15251 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 34 | batch = 5 | loss = 1.12360 |\n",
      "\n",
      "\n",
      " Test_loss= 2.802187158947899 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1872389237085976 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2021999756495159 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8252829313278198 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2913939158121746 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.21296493212382 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 35 | batch = 1 | loss = 1.14407 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 35 | batch = 2 | loss = 1.20086 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 35 | batch = 3 | loss = 1.24261 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 35 | batch = 4 | loss = 1.09401 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 35 | batch = 5 | loss = 1.11416 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7539366937818985 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2462331374486288 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2751724024613698 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8701776266098022 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1066539287567139 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.1828826268514 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 36 | batch = 1 | loss = 1.12811 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 36 | batch = 2 | loss = 1.12232 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 36 | batch = 3 | loss = 1.16084 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 36 | batch = 4 | loss = 1.20567 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 36 | batch = 5 | loss = 1.09750 |\n",
      "\n",
      "\n",
      " Test_loss= 2.743554643222264 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1972277998924254 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2182462910811107 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8077479402224222 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1763817469278972 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9831971724828084 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 37 | batch = 1 | loss = 1.15408 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 37 | batch = 2 | loss = 1.16478 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 37 | batch = 3 | loss = 1.09547 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 37 | batch = 4 | loss = 1.08189 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 37 | batch = 5 | loss = 1.11337 |\n",
      "\n",
      "\n",
      " Test_loss= 2.640509349959237 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.0612516164779664 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1854049861431122 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8046059012413025 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1206239064534504 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0700945059458413 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 38 | batch = 1 | loss = 1.14221 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 38 | batch = 2 | loss = 1.01898 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 38 | batch = 3 | loss = 1.14641 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 38 | batch = 4 | loss = 1.15751 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 38 | batch = 5 | loss = 1.08267 |\n",
      "\n",
      "\n",
      " Test_loss= 2.685864664259411 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.092177402973175 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.0925378501415253 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7384785811106364 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1656548182169597 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.964798132578532 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 39 | batch = 1 | loss = 1.12302 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 39 | batch = 2 | loss = 1.16937 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 39 | batch = 3 | loss = 1.24263 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 39 | batch = 4 | loss = 1.21677 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 39 | batch = 5 | loss = 1.20544 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7421601102465676 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2141241312026978 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2070372899373372 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8721125920613607 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.254331151644389 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.8254521290461223 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 40 | batch = 1 | loss = 1.14474 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 40 | batch = 2 | loss = 1.13344 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 40 | batch = 3 | loss = 1.08301 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 40 | batch = 4 | loss = 1.08262 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 40 | batch = 5 | loss = 1.15340 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7131230490548273 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.350373109181722 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.3978741466999054 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9852195978164673 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2553779284159343 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0717527071634927 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 41 | batch = 1 | loss = 1.13376 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 41 | batch = 2 | loss = 1.10528 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 41 | batch = 3 | loss = 1.07209 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 41 | batch = 4 | loss = 1.06084 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 41 | batch = 5 | loss = 1.12156 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7988966760181246 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1879698276519777 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2260172367095947 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8623903592427572 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3990745544433594 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.015565792719523 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 42 | batch = 1 | loss = 1.01780 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 42 | batch = 2 | loss = 1.19101 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 42 | batch = 3 | loss = 1.07338 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 42 | batch = 4 | loss = 1.07466 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 42 | batch = 5 | loss = 1.14814 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6228393089203608 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.0725680271784463 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1127239962418873 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7433886329332987 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1898064215977986 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.8977955182393391 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 43 | batch = 1 | loss = 1.16580 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 43 | batch = 2 | loss = 1.09398 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 43 | batch = 3 | loss = 1.03923 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 43 | batch = 4 | loss = 1.07853 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 43 | batch = 5 | loss = 1.11352 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6652349006562 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.185960833231608 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1964495281378429 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8685124317804972 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2352239688237507 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.146366278330485 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 44 | batch = 1 | loss = 1.06679 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 44 | batch = 2 | loss = 1.06929 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 44 | batch = 3 | loss = 1.04521 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 44 | batch = 4 | loss = 1.14145 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 44 | batch = 5 | loss = 1.11688 |\n",
      "\n",
      "\n",
      " Test_loss= 2.683046738306681 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2880551894505818 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2791528701782227 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9427556196848551 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3583192427953084 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.936070402463277 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 45 | batch = 1 | loss = 1.14585 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 45 | batch = 2 | loss = 0.99780 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 45 | batch = 3 | loss = 1.02489 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 45 | batch = 4 | loss = 1.11170 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 45 | batch = 5 | loss = 1.10621 |\n",
      "\n",
      "\n",
      " Test_loss= 2.4858069306328185 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.0047118504842123 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.0127412229776382 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.698255737622579 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2633954286575317 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.7818159262339275 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 46 | batch = 1 | loss = 1.10260 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 46 | batch = 2 | loss = 1.19932 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 46 | batch = 3 | loss = 1.05055 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 46 | batch = 4 | loss = 1.06975 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 46 | batch = 5 | loss = 1.06735 |\n",
      "\n",
      "\n",
      " Test_loss= 2.71868968577612 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.2404792070388793 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2934102018674214 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9525867501894633 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.463252584139506 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.1614935398101807 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 47 | batch = 1 | loss = 1.08545 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 47 | batch = 2 | loss = 1.12954 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 47 | batch = 3 | loss = 1.02424 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 47 | batch = 4 | loss = 1.07697 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 47 | batch = 5 | loss = 1.13186 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7411449352900186 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1623084306716918 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1817969431479771 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8119188149770101 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2917364438374836 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9253440697987874 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 48 | batch = 1 | loss = 1.01949 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 48 | batch = 2 | loss = 1.09401 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 48 | batch = 3 | loss = 1.11506 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 48 | batch = 4 | loss = 1.08036 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 48 | batch = 5 | loss = 1.01417 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7800418989998956 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.109339980284373 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1906956533590953 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8157397707303365 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3202280203501384 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9416719277699788 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 49 | batch = 1 | loss = 0.95909 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 49 | batch = 2 | loss = 1.07888 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 49 | batch = 3 | loss = 1.05682 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 49 | batch = 4 | loss = 1.11549 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 49 | batch = 5 | loss = 1.08171 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6317101887294228 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.0205094536145527 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.0742525060971577 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.727748453617096 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2803256511688232 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9640103975931804 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 50 | batch = 1 | loss = 1.07126 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 50 | batch = 2 | loss = 0.98703 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 50 | batch = 3 | loss = 1.07117 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 50 | batch = 4 | loss = 1.10544 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 50 | batch = 5 | loss = 1.02212 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7637291181655157 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.246968364715576 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2174421846866608 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.9431941906611124 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4779633283615112 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.074621597925822 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 51 | batch = 1 | loss = 1.10995 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 51 | batch = 2 | loss = 1.04400 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 51 | batch = 3 | loss = 0.98774 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 51 | batch = 4 | loss = 0.96182 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 51 | batch = 5 | loss = 1.06101 |\n",
      "\n",
      "\n",
      " Test_loss= 2.5266456263405934 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.0997683564821878 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1297167738278706 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8179325064023336 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2308186690012615 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9295104344685872 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 52 | batch = 1 | loss = 1.02197 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 52 | batch = 2 | loss = 1.04041 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 52 | batch = 3 | loss = 0.96981 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 52 | batch = 4 | loss = 1.06452 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 52 | batch = 5 | loss = 1.06351 |\n",
      "\n",
      "\n",
      " Test_loss= 2.820471508162362 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.6054119269053142 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.6480798224608104 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 1.3247706095377605 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.5558509826660156 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0879982709884644 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 53 | batch = 1 | loss = 1.04916 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 53 | batch = 2 | loss = 1.03250 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 53 | batch = 3 | loss = 0.96998 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 53 | batch = 4 | loss = 1.07258 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 53 | batch = 5 | loss = 1.04950 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6312342087427774 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1406952182451884 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2039926052093506 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8590895930926005 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.5592966477076213 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.781109889348348 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 54 | batch = 1 | loss = 1.01430 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 54 | batch = 2 | loss = 1.00995 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 54 | batch = 3 | loss = 1.07723 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 54 | batch = 4 | loss = 1.04807 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 54 | batch = 5 | loss = 0.99400 |\n",
      "\n",
      "\n",
      " Test_loss= 2.748711251077198 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1707614739735923 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.2224075496196747 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8492070237795512 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2877688805262248 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.2336216370264688 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 55 | batch = 1 | loss = 1.03410 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 55 | batch = 2 | loss = 0.98825 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 55 | batch = 3 | loss = 0.93785 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 55 | batch = 4 | loss = 1.09867 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 55 | batch = 5 | loss = 1.06675 |\n",
      "\n",
      "\n",
      " Test_loss= 2.500098285220918 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 0.9920935034751892 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.0353895823160808 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7480551799138387 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.323399027188619 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.163597265879313 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 56 | batch = 1 | loss = 0.94926 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 56 | batch = 2 | loss = 1.06614 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 56 | batch = 3 | loss = 1.04191 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 56 | batch = 4 | loss = 1.01139 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 56 | batch = 5 | loss = 1.01850 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6263036160241993 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.1710644801457721 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1967177987098694 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8573804299036661 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2191747824350994 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.1954424381256104 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 57 | batch = 1 | loss = 0.98840 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 57 | batch = 2 | loss = 1.00538 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 57 | batch = 3 | loss = 0.96675 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 57 | batch = 4 | loss = 1.06036 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 57 | batch = 5 | loss = 0.93347 |\n",
      "\n",
      "\n",
      " Test_loss= 2.5553958756583075 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 0.9744043747584025 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.0140994588534038 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7125338912010193 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.1878904898961384 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.9397650162378948 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 58 | batch = 1 | loss = 1.00161 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 58 | batch = 2 | loss = 0.97946 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 58 | batch = 3 | loss = 1.08777 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 58 | batch = 4 | loss = 0.99269 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 58 | batch = 5 | loss = 0.97723 |\n",
      "\n",
      "\n",
      " Test_loss= 2.464552192460923 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 0.9962542851765951 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 0.9707373032967249 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.6558177868525187 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.2383114099502563 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.0741477807362876 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 59 | batch = 1 | loss = 0.97036 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 59 | batch = 2 | loss = 0.99607 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 59 | batch = 3 | loss = 1.01012 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 59 | batch = 4 | loss = 0.93980 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 59 | batch = 5 | loss = 1.01472 |\n",
      "\n",
      "\n",
      " Test_loss= 2.6260320459093367 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.12110009988149 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1205904632806778 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.8207217256228129 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.3708382844924927 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 1.892036000887553 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Stepping backward.\n",
      "| epoch = 60 | batch = 1 | loss = 1.02981 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 60 | batch = 2 | loss = 0.96593 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 60 | batch = 3 | loss = 0.98131 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 60 | batch = 4 | loss = 0.94967 |\n",
      "\n",
      "Stepping backward.\n",
      "| epoch = 60 | batch = 5 | loss = 1.00580 |\n",
      "\n",
      "\n",
      " Test_loss= 2.7228926874342423 Test_type= BatchType.obfuscated_formai\n",
      "\n",
      " Test_loss= 1.0809408545494081 Test_type= BatchType.optim_level_formai\n",
      "\n",
      " Test_loss= 1.1002850035826366 Test_type= BatchType.mutated_optim_levels_formai\n",
      "\n",
      " Test_loss= 0.7471882104873657 Test_type= BatchType.mutated_formai\n",
      "\n",
      " Test_loss= 1.4967517058054607 Test_type= BatchType.mutated_wasm_bench\n",
      "\n",
      " Test_loss= 2.121868848800659 Test_type= BatchType.mutated_msr\n",
      "\n",
      " Test_loss= 0.0 Test_type= BatchType.semantic_classification\n",
      "Saving trainable_model.name='Emprique60_2_ResBin18_woSA_b64_i64_pil_v128_rmax_t015'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps'\n",
    "\n",
    "temperatures = [\n",
    "    0.15,\n",
    "]\n",
    "for reduction in [\n",
    "    'max'\n",
    "]:\n",
    "\n",
    "    for temp in temperatures:\n",
    "\n",
    "        print('Training ')\n",
    "\n",
    "        vec_size = 128 if reduction is not None else 512\n",
    "        hidden_size = 128 if reduction is not None else 256\n",
    "        out_size = 128\n",
    "\n",
    "        backbone, model_name = (\n",
    "            ConvRes(att=False, reduction=reduction, ll=3), \n",
    "            f'Emprique60_2_ResBin18_woSA_b64_i{size}_pil_v{vec_size}_r{reduction}',\n",
    "        )\n",
    "\n",
    "        criterion, is_for_simclr = lightly.loss.NTXentLoss(\n",
    "            temperature=temp,\n",
    "            memory_bank_size=0,\n",
    "        ), True\n",
    "        name = model_name + f'_t{criterion.temperature}'.replace('.','')\n",
    "\n",
    "        model = wasmshield.models.conv.ConvNet(\n",
    "            img_size=size,\n",
    "            backbone=backbone,\n",
    "            vec_size=vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            out_size=out_size,\n",
    "            use_head=True\n",
    "        )\n",
    "\n",
    "        trainable_model = wasmshield.training.trainer.TrainableModel(\n",
    "            model=model,\n",
    "            name=name,\n",
    "            device=device\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(trainable_model.model.parameters(), lr=0.0025, weight_decay=0)\n",
    "\n",
    "        trainer = wasmshield.training.trainer.Trainer(\n",
    "            trainable_model=trainable_model,\n",
    "            optimizer=optimizer,\n",
    "            preprocessor=lambda *args, **kwargs:wasmshield.preprocessing.preprocess_image(*args,**kwargs, use_pil=True, compress=False, size=size),\n",
    "            training_preprocessor=wasmshield.preprocessing.preprocess_image_for_training,\n",
    "            formai_dataset=(train_set, test_set),\n",
    "            obfuscated_formai_dataset=(obfuscated_train_set, obfuscated_test_set),\n",
    "            wasm_bench_dataset=(wasm_bench_train_set, wasm_bench_test_set),\n",
    "            msr_dataset=(msr_train_set, msr_test_set),\n",
    "            semantic_dataset=(semantic_X, semantic_y, semantic_train_idx, semantic_test_idx),\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        batch_types_levels = [\n",
    "            (60,[\n",
    "                wasmshield.training.trainer.BatchType.obfuscated_formai,\n",
    "                wasmshield.training.trainer.BatchType.mutated_formai,\n",
    "                wasmshield.training.trainer.BatchType.mutated_optim_levels_formai,\n",
    "                wasmshield.training.trainer.BatchType.optim_level_formai,\n",
    "                wasmshield.training.trainer.BatchType.mutated_wasm_bench,\n",
    "                wasmshield.training.trainer.BatchType.mutated_msr,\n",
    "                wasmshield.training.trainer.BatchType.semantic_classification,\n",
    "            ]), \n",
    "        ]\n",
    "\n",
    "        n_reps_per_batch = {\n",
    "            wasmshield.training.trainer.BatchType.obfuscated_formai : 7,\n",
    "            wasmshield.training.trainer.BatchType.mutated_formai : 1,\n",
    "            wasmshield.training.trainer.BatchType.optim_level_formai : 5,\n",
    "            wasmshield.training.trainer.BatchType.mutated_optim_levels_formai : 4,\n",
    "            wasmshield.training.trainer.BatchType.mutated_msr : 1,\n",
    "            wasmshield.training.trainer.BatchType.mutated_wasm_bench : 1,\n",
    "            wasmshield.training.trainer.BatchType.semantic_classification : 0,\n",
    "        }\n",
    "\n",
    "        batch_types = []\n",
    "        criterion_semantic = nn.CrossEntropyLoss()\n",
    "        batch_size = 64\n",
    "        n_batches_per_epoch = 5\n",
    "\n",
    "        batch_size_semantic=256\n",
    "        max_batch_size = 64\n",
    "\n",
    "        print('Training', f'{trainable_model.name=}')\n",
    "\n",
    "        for nb_epochs,bt in batch_types_levels:\n",
    "            \n",
    "            batch_types = bt\n",
    "            print('')\n",
    "            print('='*10)\n",
    "            print(bt)\n",
    "            print('='*10)\n",
    "\n",
    "            trainer.train(\n",
    "                startepoch=trainable_model.epoch,\n",
    "                nbepochs=trainable_model.epoch+nb_epochs,\n",
    "                batch_size=batch_size,\n",
    "                max_batch_size=max_batch_size,\n",
    "                batch_types=list((batch_types)),\n",
    "                n_reps_per_batch=n_reps_per_batch,\n",
    "                n_batches_per_epoch=n_batches_per_epoch,\n",
    "                criterion=criterion,\n",
    "                do_shuffle=True,\n",
    "                semantic_mlp=torch.nn.Identity(),\n",
    "                criterion_semantic=criterion_semantic,\n",
    "                batch_size_semantic=batch_size_semantic,\n",
    "            )\n",
    "        \n",
    "        print('Saving', f\"{trainable_model.name=}\")\n",
    "        trainable_model.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
